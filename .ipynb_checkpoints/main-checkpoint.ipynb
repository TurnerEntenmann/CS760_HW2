{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz, sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.lines as mlines\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fxn for plotting\n",
    "def get_ax(figsize=(6,4)):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D is the name of the data file\n",
    "# returns a df with columns x_1, x_2, y of float values\n",
    "def read_data(D):\n",
    "    df = pd.read_csv(\"data/\"+D, sep = \" \", names = [\"x_1\", \"x_2\", \"y\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D is a df\n",
    "# returns a list of (feature, canidate split) tuples\n",
    "def determine_candidate_splits(D):\n",
    "    # init list of canidate splits\n",
    "    C = []\n",
    "    # loop through both features\n",
    "    for feature in [\"x_1\", \"x_2\"]:\n",
    "        # data_points is the feature and y columns of D into a df, sorted by X_i with idx 0, 1, 2, ...\n",
    "        data_points = D[[feature, \"y\"]].sort_values(by=feature).reset_index(drop=True)\n",
    "        \n",
    "        # loop through data_df, read next value, label and next label\n",
    "        for j in range(len(D)-1):\n",
    "            val = data_points[feature][j+1]\n",
    "            lab_1 = data_points[\"y\"][j]\n",
    "            lab_2 = data_points[\"y\"][j+1]\n",
    "            \n",
    "            # check if adjacent labels mis-match, if True: append feature and val to C\n",
    "            if lab_1 != lab_2:\n",
    "                C.append((feature, val))\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column is the lab column of D\n",
    "# returns entropy of D[lab]\n",
    "def H(Column):\n",
    "    # get unique values and corresponding counts\n",
    "    u_vals, u_counts = np.unique(Column, return_counts=True, axis=0)\n",
    "    # counts to probabilities\n",
    "    probs = u_counts/len(Column)\n",
    "    # entropy fxn\n",
    "    return np.sum((-1)*probs*np.log2(probs))\n",
    "\n",
    "# D is a sorted df, idx is the index of the split\n",
    "# returns (entropy of the split, conditional entropy)\n",
    "def H_split(D, idx):   \n",
    "    # get Y lists after split\n",
    "    Y_1 = D[\"y\"][:idx]\n",
    "    Y_2 = D[\"y\"][idx:]\n",
    "\n",
    "    # ratio of the size of Y_i's vs whole set\n",
    "    ratio_1 = len(Y_1) / len(D[\"y\"])\n",
    "    ratio_2 = len(Y_2) / len(D[\"y\"])\n",
    "\n",
    "    # entropy of Y given the split\n",
    "    c_ent = (H(Y_1) * ratio_1) + (H(Y_2) * ratio_2)\n",
    "\n",
    "    # entropy of the split\n",
    "    H_s = 0\n",
    "    # avoid log(0)\n",
    "    if ratio_1 != 0:\n",
    "        H_s += -(ratio_1 * np.log2(ratio_1))\n",
    "    if ratio_2 != 0:\n",
    "        H_s += -(ratio_2 * np.log2(ratio_2))\n",
    "    return H_s, c_ent\n",
    "\n",
    "\n",
    "# D is the data df, feature is \"x_i\", candidate is the splitter\n",
    "# returns the gain ratio of the candidate split\n",
    "def gain_ratio(D, feature, candidate):\n",
    "    # entropy of untouched Y\n",
    "    H_Y = H(D[\"y\"])\n",
    "    \n",
    "    # get index of split\n",
    "    D = D.sort_values(by=feature).reset_index(drop=True)\n",
    "    idx = D[D[feature] == candidate].index.astype(int)[0]\n",
    "\n",
    "    # get split entropy and conditional entropy\n",
    "    H_s, c_ent = H_split(D, idx)\n",
    "    # avoid 0 division\n",
    "    if H_s != 0:    \n",
    "        val = (H_Y - c_ent) / H_s\n",
    "    else:\n",
    "        val = None\n",
    "    return val\n",
    "\n",
    "# D is the data df, C is the candidate split list [(feature, split value), ...]\n",
    "# returns (list of partitions, best feature, best splitter)\n",
    "def find_best_split(D, C):\n",
    "    # find best split\n",
    "    # init best stuff\n",
    "    best_feature = None\n",
    "    best_splitter = None\n",
    "    best_GR = 0\n",
    "    \n",
    "    # loop through C, find each gain ratio\n",
    "    for feature, candidate in C:\n",
    "        trial_GR = gain_ratio(D, feature, candidate)\n",
    "        # avoid none type\n",
    "        if trial_GR == None:\n",
    "            continue\n",
    "        # see if it is better than previous best\n",
    "        if trial_GR > best_GR:\n",
    "            best_feature = feature\n",
    "            best_splitter = candidate\n",
    "            best_GR = trial_GR\n",
    "      \n",
    "    # make split\n",
    "    # sort data and re-index\n",
    "    D = D.sort_values(by=best_feature).reset_index(drop=True)\n",
    "    \n",
    "    # find index of the splitter\n",
    "    idx = D[D[best_feature] == best_splitter].index.astype(int)[0]\n",
    "    \n",
    "    # split data into two partitions\n",
    "    smaller = D[:idx]\n",
    "    bigger = D[idx:]\n",
    "    \n",
    "    return ([bigger, smaller], [best_feature, best_splitter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node is a df, splits are candidate splits (feature, value)\n",
    "# returns a list of gains for each potential split in the node\n",
    "def make_gain_list(node, splits):\n",
    "    gains = []\n",
    "    # loop over splits and find gain ratios\n",
    "    for feature, candidate in splits:\n",
    "        gains.append(gain_ratio(node, feature, candidate))\n",
    "    return gains\n",
    "\n",
    "# lst is a list(like)\n",
    "# returns True if all values in lst are 0, False otherwise\n",
    "def is_all_zero(lst):\n",
    "    for value in lst:\n",
    "        if value != 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# node is a df, splits are candidate splits (feature, value)\n",
    "# returns True if all can. split entropies are 0, False otherwise\n",
    "def any_zero_ents(node, splits):\n",
    "    # loop through canidate splits\n",
    "    for feature, splitter in splits:\n",
    "        # get index of the splitter\n",
    "        D = node.sort_values(by=feature).reset_index(drop=True)\n",
    "        idx = D[D[feature] == splitter].index.astype(int)[0]\n",
    "        \n",
    "        # check if each split has 0 entropy\n",
    "        if H_split(node, idx) == 0:\n",
    "            # if yes => return True\n",
    "            result = True\n",
    "            break\n",
    "        else:\n",
    "            # otherwise return False\n",
    "            result = False\n",
    "    return result\n",
    "\n",
    "# node is a df\n",
    "# returns True if node satisfies a stopping condition, False otherwise\n",
    "def is_stopper(node):\n",
    "    # list of candidate splits\n",
    "    can_splits = determine_candidate_splits(node)\n",
    "    # list of gains of possible splits\n",
    "    gain_list = make_gain_list(node, can_splits)\n",
    "    # node is empty => stop\n",
    "    if len(node) == 0:\n",
    "        result = True\n",
    "    # all splits have no gain => stop\n",
    "    elif is_all_zero(gain_list):\n",
    "        result = True\n",
    "    # any candidate has 0 entropy => stop\n",
    "    elif any_zero_ents(node, can_splits):\n",
    "        result = True\n",
    "    # otherwise => don't stop\n",
    "    else:\n",
    "        result = False\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g.node(name, printed label)\n",
    "# D is a df, parent is the parent node\n",
    "def make_leaf_node(D, parent, graph, leaf_number, edge_name):\n",
    "    # u_vals is [0,1] or [1,0]\n",
    "    # u_counts is a list of the corresponding counts\n",
    "    u_vals, u_counts = np.unique(D[\"y\"], return_counts=True, axis=0)\n",
    "    \n",
    "    # find majority\n",
    "    if np.sum(D[\"y\"]) >= len(D)/2:\n",
    "        label = \"1\"\n",
    "    else:\n",
    "        label = \"0\"\n",
    "\n",
    "    # make node, add to tree and increment leaf number\n",
    "    graph.node(parent + label, label)\n",
    "    graph.edge(parent, parent + label, label=edge_name)\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_internal_node(parent, label, graph, edge_name):\n",
    "    # check if node is the root\n",
    "    if parent == None:\n",
    "        graph.node(label)\n",
    "    else:\n",
    "        graph.node(label)\n",
    "        graph.edge(parent, label, label=edge_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'D3_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-62c68ad9c04b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[0mmake_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD3_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"trees/test_tree\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'D3_df' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO: get rules to make prediction\n",
    "# D is a data frame,\n",
    "def make_subtree(D, parent, g, leaf_number, edge_name, rules):\n",
    "    # check if we are at a leaf\n",
    "    if is_stopper(D):\n",
    "        make_leaf_node(D, parent, g, leaf_number, edge_name)\n",
    "    else:\n",
    "        # find best split and splitting feature\n",
    "        C = determine_candidate_splits(D)\n",
    "        S, splitting_feature = find_best_split(D, C)\n",
    "        \n",
    "        # get splitting column and value\n",
    "        s_col = splitting_feature[0]\n",
    "        s_val = splitting_feature[1]\n",
    "        \n",
    "        # make node       \n",
    "        node_name = str(s_col) + \" >= \" + str(s_val)\n",
    "        make_internal_node(parent, node_name, g, edge_name)\n",
    "        \n",
    "        rules.append((s_col, s_val))\n",
    "   \n",
    "        # loop through splits and repeat\n",
    "        # make_subtree isn't getting enough positional arguments\n",
    "        for k in S:\n",
    "            # get edge_name\n",
    "            if min(k[s_col]) == s_val:\n",
    "                edge_name = \"True\"\n",
    "            else:\n",
    "                edge_name = \"False\"\n",
    "            child_k = make_subtree(k, node_name, g, leaf_number, edge_name, rules)\n",
    "            \n",
    "# D is a df, creates and outputs the d tree\n",
    "def make_tree(D, fname):\n",
    "    rules = []\n",
    "    g = graphviz.Digraph()\n",
    "    leaf_number = 0\n",
    "    make_subtree(D, None, g, leaf_number, None, rules)\n",
    "    g.render(fname)\n",
    "    #print(rules)\n",
    "    return g\n",
    "\n",
    "def predict_point(x_1, x_2, tree):\n",
    "    pass\n",
    "\n",
    "# make_tree(D3_df, \"trees/test_tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_point(x_1, x_2, tree):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_point(1, 5, [('x_2', 2), ('x_1', 10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D1_df = read_data(\"D1.txt\")\n",
    "make_tree(D1_df, \"trees/D1_tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D2_df = read_data(\"D2.txt\")\n",
    "make_tree(D2_df, \"trees/D2_tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Druns_df = read_data(\"Druns.txt\")\n",
    "make_tree(Druns_df, \"trees/Druns_tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3\n",
    "# get data\n",
    "druns_splits = determine_candidate_splits(Druns_df)\n",
    "druns_gains = make_gain_list(Druns_df, druns_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find candidate splits and gain ratio\n",
    "for i in range(len(druns_splits)):\n",
    "    print(\"feature:\", druns_splits[i][0], \"\\n\", \"splitter:\", druns_splits[i][1], \"\\n\", \"gain ratio:\", druns_gains[i], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D3_df = read_data(\"D3leaves.txt\")\n",
    "make_tree(D3_df, \"trees/D3_tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make axies\n",
    "ax = get_ax()\n",
    "\n",
    "# set colors (colorblind friendly via https://yoshke.org/blog/colorblind-friendly-diagrams)\n",
    "colors = {0: '#000000', 1: '#E69F00'}\n",
    "\n",
    "# make plot\n",
    "D1_df.plot.scatter(x=\"x_1\", y=\"x_2\", c=D1_df[\"y\"].map(colors), ax=ax)\n",
    "\n",
    "# plot settings\n",
    "fsize = 15\n",
    "# legend\n",
    "b_dot = mlines.Line2D([], [], color='#000000', marker='.', linestyle='None',\n",
    "                          markersize=10, label='0')\n",
    "o_dot = mlines.Line2D([], [], color='#E69F00', marker='.', linestyle='None',\n",
    "                          markersize=10, label='1')\n",
    "ax.legend(handles=[b_dot, o_dot], fontsize=fsize, bbox_to_anchor=(1, 1), frameon=False)\n",
    "\n",
    "# axies\n",
    "plt.xticks(size=fsize)\n",
    "plt.yticks(size=fsize)\n",
    "plt.xlabel(\"$x_1$\", size=fsize)\n",
    "plt.ylabel(\"$x_2$\", size=fsize)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plots/D1_plot.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make axies\n",
    "ax = get_ax()\n",
    "\n",
    "\n",
    "# set colors (colorblind friendly via https://yoshke.org/blog/colorblind-friendly-diagrams)\n",
    "colors = {0: '#000000', 1: '#E69F00'}\n",
    "\n",
    "# make plot\n",
    "D2_df.plot.scatter(x=\"x_1\", y=\"x_2\", c=D2_df[\"y\"].map(colors), ax=ax)\n",
    "\n",
    "# plot settings\n",
    "fsize = 15\n",
    "# legend\n",
    "b_dot = mlines.Line2D([], [], color='#000000', marker='.', linestyle='None',\n",
    "                          markersize=10, label='0')\n",
    "o_dot = mlines.Line2D([], [], color='#E69F00', marker='.', linestyle='None',\n",
    "                          markersize=10, label='1')\n",
    "ax.legend(handles=[b_dot, o_dot], fontsize=fsize, bbox_to_anchor=(1, 1), frameon=False)\n",
    "\n",
    "# axies\n",
    "plt.xticks(size=fsize)\n",
    "plt.yticks(size=fsize)\n",
    "plt.xlabel(\"$x_1$\", size=fsize)\n",
    "plt.ylabel(\"$x_2$\", size=fsize)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plots/D2_plot.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dbig_df = read_data(\"DBig.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scramble and split Dbig_df\n",
    "scrambled_idxs = np.random.permutation(len(Dbig_df))\n",
    "\n",
    "train_idxs = scrambled_idxs[:8192]\n",
    "D8192_df = Dbig_df.iloc[train_idxs]\n",
    "\n",
    "test_idxs = scrambled_idxs[8192:]\n",
    "test_df = Dbig_df.iloc[test_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training subsets\n",
    "D2048_df = D8192_df[:2048]\n",
    "D512_df = D8192_df[:512]\n",
    "D128_df = D8192_df[:128]\n",
    "D32_df = D8192_df[:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make trees\n",
    "#make_tree(D2048_df, \"trees/D2048_tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot error fxn\n",
    "def Q3(D):\n",
    "    sk_tree = DecisionTreeClassifier()\n",
    "    sk_tree.fit(D[[\"x_1\", \"x_2\"]], D[\"y\"])\n",
    "    \n",
    "    num_nodes = sk_tree.tree_.node_count\n",
    "    predictions = sk_tree.predict(test_df[[\"x_1\", \"x_2\"]])\n",
    "\n",
    "    error = sum(np.abs(predictions - test_df[\"y\"]))\n",
    "    \n",
    "    return num_nodes, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3(D2048_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3(D512_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3(D128_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3(D32_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_dtree = DecisionTreeClassifier()\n",
    "\n",
    "sk_dtree.fit(D1_df[[\"x_1\", \"x_2\"]], D1_df[\"y\"])\n",
    "\n",
    "sklearn.tree.plot_tree(sk_dtree)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
